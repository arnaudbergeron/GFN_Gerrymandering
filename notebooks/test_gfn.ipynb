{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.0 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/opt/anaconda3/envs/gfn/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/anaconda3/envs/gfn/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/arnaudbergeron/.local/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/arnaudbergeron/.local/lib/python3.10/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/arnaudbergeron/.local/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 725, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/arnaudbergeron/.local/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/anaconda3/envs/gfn/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/anaconda3/envs/gfn/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/anaconda3/envs/gfn/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/arnaudbergeron/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/arnaudbergeron/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/arnaudbergeron/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/arnaudbergeron/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/arnaudbergeron/.local/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/arnaudbergeron/.local/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/arnaudbergeron/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/arnaudbergeron/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/arnaudbergeron/.local/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/arnaudbergeron/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/arnaudbergeron/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/arnaudbergeron/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/gv/7cc2bxmj0p73_3743hzyf9xr0000gn/T/ipykernel_643/565215865.py\", line 1, in <module>\n",
      "    from gfn.states import States\n",
      "  File \"/opt/anaconda3/envs/gfn/lib/python3.10/site-packages/gfn/states.py\", line 8, in <module>\n",
      "    import torch\n",
      "  File \"/opt/anaconda3/envs/gfn/lib/python3.10/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/opt/anaconda3/envs/gfn/lib/python3.10/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/opt/anaconda3/envs/gfn/lib/python3.10/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/opt/anaconda3/envs/gfn/lib/python3.10/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/opt/anaconda3/envs/gfn/lib/python3.10/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/opt/anaconda3/envs/gfn/lib/python3.10/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    }
   ],
   "source": [
    "from gfn.states import States\n",
    "from gfn.utils.common import set_seed\n",
    "from gfn.utils.modules import MLP  # is a simple multi-layer perceptron (MLP)\n",
    "from torch.distributions import Distribution, Normal  # TODO: extend to Beta\n",
    "from torch.distributions.independent import Independent\n",
    "from tqdm import tqdm, trange\n",
    "from gfn.modules import DiscretePolicyEstimator\n",
    "from gfn.gflownet import TBGFlowNet\n",
    "import torch\n",
    "from common.env import DistrictEnv\n",
    "from common.pe_sampler import DistrictSampler, DistrictPolicyEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = DistrictEnv(json_file=\"data/IA_raw_data.json\", device_str=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fw_dim = env.state_shape[0]\n",
    "n_actions = env.n_actions[0]\n",
    "\n",
    "module_PF = MLP(\n",
    "    input_dim=fw_dim,\n",
    "    output_dim=n_actions\n",
    ")  # Neural network for the forward policy, with as many outputs as there are actions\n",
    "\n",
    "module_PB = MLP(\n",
    "    input_dim=fw_dim,\n",
    "    output_dim=n_actions - 1,\n",
    "    trunk=module_PF.trunk  # We share all the parameters of P_F and P_B, except for the last layer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf_estimator = DistrictPolicyEstimator(module_PF, env.n_actions, is_backward=False, preprocessor=env.preprocessor)\n",
    "pb_estimator = DistrictPolicyEstimator(module_PB, env.n_actions, is_backward=True, preprocessor=env.preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "DistrictState.__init__() missing 1 required positional argument: 'is_sink'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# 6 - We train the GFlowNet for 1000 iterations, with 16 trajectories per iteration\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m (pbar \u001b[38;5;241m:=\u001b[39m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1000\u001b[39m))):\n\u001b[0;32m---> 13\u001b[0m     trajectories \u001b[38;5;241m=\u001b[39m \u001b[43msampler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_trajectories\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     15\u001b[0m     loss \u001b[38;5;241m=\u001b[39m gfn\u001b[38;5;241m.\u001b[39mloss(env, trajectories)\n",
      "File \u001b[0;32m~/Desktop/School/Masters/Fall_2024/PSET/RL/final_proj/GFN_Gerrymandering/common/pe_sampler.py:216\u001b[0m, in \u001b[0;36mDistrictSampler.sample_trajectories\u001b[0;34m(self, env, n, states, conditioning, save_estimator_outputs, save_logprobs, **policy_kwargs)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    212\u001b[0m     masked_conditioning \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    214\u001b[0m valid_actions, actions_log_probs, estimator_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample_actions(\n\u001b[1;32m    215\u001b[0m     env,\n\u001b[0;32m--> 216\u001b[0m     \u001b[43mstates\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m~\u001b[39;49m\u001b[43mdones\u001b[49m\u001b[43m]\u001b[49m,\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpolicy_kwargs,\n\u001b[1;32m    218\u001b[0m )\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# Place estimator outputs into a stackable tensor. Note that this\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# will be replaced with torch.nested.nested_tensor in the future.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     estimator_outputs_padded \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfull(\n\u001b[1;32m    223\u001b[0m         (n_trajectories,) \u001b[38;5;241m+\u001b[39m estimator_outputs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    224\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    225\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat,\n\u001b[1;32m    226\u001b[0m         device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[1;32m    227\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/gfn/lib/python3.10/site-packages/gfn/states.py:142\u001b[0m, in \u001b[0;36mStates.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28mself\u001b[39m, index: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m Sequence[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m|\u001b[39m Sequence[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m|\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor\n\u001b[1;32m    140\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m States:\n\u001b[1;32m    141\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Access particular states of the batch.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 142\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# TODO: Inefficient - this might make a copy of the tensor!\u001b[39;00m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_rewards \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m         out\u001b[38;5;241m.\u001b[39mlog_rewards \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_rewards[index]\n",
      "\u001b[0;31mTypeError\u001b[0m: DistrictState.__init__() missing 1 required positional argument: 'is_sink'"
     ]
    }
   ],
   "source": [
    "gfn = TBGFlowNet(logZ=0., pf=pf_estimator, pb=pb_estimator)  # We initialize logZ to 0\n",
    "\n",
    "# 5 - We define the sampler and the optimizer.\n",
    "sampler = DistrictSampler(estimator=pf_estimator)  # We use an on-policy sampler, based on the forward policy\n",
    "\n",
    "# Different policy parameters can have their own LR.\n",
    "# Log Z gets dedicated learning rate (typically higher).\n",
    "optimizer = torch.optim.Adam(gfn.pf_pb_parameters(), lr=1e-3)\n",
    "optimizer.add_param_group({\"params\": gfn.logz_parameters(), \"lr\": 1e-1})\n",
    "\n",
    "# 6 - We train the GFlowNet for 1000 iterations, with 16 trajectories per iteration\n",
    "for i in (pbar := tqdm(range(1000))):\n",
    "    trajectories = sampler.sample_trajectories(env=env, n=16)\n",
    "    optimizer.zero_grad()\n",
    "    loss = gfn.loss(env, trajectories)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i % 25 == 0:\n",
    "        pbar.set_postfix({\"loss\": loss.item()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gfn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
